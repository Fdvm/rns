{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pymysql\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Federico\\\\Desktop\\\\Broker\\\\RNS\\\\src')\n",
    "import rns_functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths\n",
    "file_path = '../data/2019/registro-nacional-sociedades-201909.csv'\n",
    "file_next_date = pd.to_datetime(file_path[-10:-4]+'01') + pd.DateOffset(months= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ****************** VALIDACIONES GENERALES ********************\n",
    "\n",
    "## -------------------- HEADERS -----------------------\n",
    "\n",
    "with open(f'../logs/log_{file_path[-10:-4]}.txt', 'w+') as log:\n",
    "        log.write(f'Cargando el archivo -> {file_path[13:]}\\r\\n')\n",
    "        \n",
    "with open('../data/headers.csv', 'r', encoding= 'utf-8-sig') as f:\n",
    "    headers = f.readline().replace('\\n','').split(',')\n",
    "        \n",
    "try:\n",
    "        \n",
    "    F.f_check_headers(file_path)\n",
    "    \n",
    "    rns = pd.read_csv(file_path, header= 0, dtype= 'string').drop(columns= 'numero_inscripcion')\n",
    "\n",
    "    with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "            log.write('Archivo cargado\\r\\n')\n",
    "        \n",
    "except Warning:\n",
    "    \n",
    "    rns = pd.read_csv(file_path, header= None, names= headers, dtype= 'string').drop(columns= 'numero_inscripcion')\n",
    "    \n",
    "    with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "            log.write('Warning: Archivo cargado, no hay Headers\\r\\n')\n",
    "    \n",
    "except ValueError:\n",
    "    \n",
    "    with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "            log.write('Error: Archivo no cargado, hay campos distintos a los esperados\\r\\n')\n",
    "\n",
    "## ---------------- FILE COLUMNS ----------------------\n",
    "\n",
    "# Procesamiento\n",
    "\n",
    "strings = ['razon_social', 'tipo_societario', 'dom_fiscal_provincia',\n",
    "           'dom_fiscal_localidad', 'dom_fiscal_calle', 'dom_fiscal_piso',\n",
    "           'dom_fiscal_departamento', 'dom_fiscal_estado_domicilio', 'dom_legal_provincia',\n",
    "           'dom_legal_localidad', 'dom_legal_calle', 'dom_legal_piso', 'dom_legal_departamento',\n",
    "           'dom_legal_estado_domicilio']\n",
    "\n",
    "# Lower todos los tipos strings\n",
    "rns.loc[:,strings] = rns[strings].apply(lambda x: F.f_proceso_string(x))\n",
    "\n",
    "# Corrijo la fecha de constitucion para ser YYYY-MM-DD\n",
    "rns['fh_contrato_social'] = rns['fecha_contrato_social'].str[:10] \n",
    "rns['fh_contrato_social'] = pd.to_datetime(rns['fh_contrato_social'], errors= 'coerce')\n",
    "rns.loc[rns['fh_contrato_social'] >= file_next_date, 'fh_contrato_social'] = np.NaN\n",
    "\n",
    "# Lo mismo hago con la fecha de la ultima actualizacion\n",
    "rns['fh_actualizacion'] = rns['fecha_actualizacion'].str[:10] \n",
    "rns['fh_actualizacion'] = pd.to_datetime(rns['fh_actualizacion'], errors= 'coerce')\n",
    "rns.loc[rns['fh_actualizacion'] >= file_next_date, 'fh_actualizacion'] = np.NaN\n",
    "\n",
    "# Pongo en Integer el Codigo Postal y el domicilio \n",
    "rns['dom_fiscal_cp'] = pd.to_numeric(rns['dom_fiscal_cp'], errors= 'coerce').astype('Int64')\n",
    "rns['dom_legal_cp'] = pd.to_numeric(rns['dom_legal_cp'], errors= 'coerce').astype('Int64')\n",
    "rns['dom_fiscal_numero'] = pd.to_numeric(rns['dom_fiscal_numero'], errors= 'coerce').astype('Int64')\n",
    "rns['dom_legal_numero'] = pd.to_numeric(rns['dom_legal_numero'], errors= 'coerce').astype('Int64')\n",
    "\n",
    "# Valido la estructura de los CUITs\n",
    "rns['cuit_valido'] = F.f_cuit_validation(rns['cuit'])\n",
    "\n",
    "# Validacion NAs\n",
    "columnas = ['razon_social','fh_contrato_social','tipo_societario','fh_actualizacion','dom_fiscal_provincia','dom_fiscal_localidad','dom_fiscal_calle','dom_fiscal_numero','dom_fiscal_piso','dom_fiscal_departamento','dom_fiscal_cp','dom_fiscal_estado_domicilio','dom_legal_provincia','dom_legal_localidad','dom_legal_calle','dom_legal_numero','dom_legal_piso','dom_legal_departamento','dom_legal_cp','dom_legal_estado_domicilio']\n",
    "nulos = rns[columnas].isnull().mean()\n",
    "\n",
    "with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "    \n",
    "    log.write('NROWS: {}\\r\\n'.format(rns.shape[0]))\n",
    "    log.write('CUITS OK: {} ; CUITS No Validos: {} ; CUITS NAs: {}\\r\\n'.format(rns['cuit_valido'].sum(),(~rns['cuit_valido']).sum(),rns['cuit'].isnull().sum()))\n",
    "    \n",
    "    if rns['cuit_valido'].sum() == rns.shape[0]:\n",
    "        log.write('NROWS = CUITS -> OK\\r\\n')\n",
    "    else:\n",
    "        log.write('NROWS = CUITS -> WARNING!!\\r\\n')\n",
    "    \n",
    "    log.write('\\r\\n'*2)\n",
    "    log.write('TABLA DE NAs:\\r\\n')\n",
    "    \n",
    "    for i in nulos.keys():\n",
    "        log.write('\\t {}: {:.2f}%\\r\\n'.format(i,nulos[i]*100))\n",
    "\n",
    "    log.write('\\r\\n'*2)\n",
    "    \n",
    "## ------------------ DROP NAs ------------------------\n",
    "\n",
    "# Estos 3 campos tienen que tener valor siempre\n",
    "invalid_rows = rns[['cuit','razon_social','fh_contrato_social']].isnull().any(axis= 1)\n",
    "rns = rns.loc[~invalid_rows,:]\n",
    "\n",
    "with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "    \n",
    "    log.write('INVALID ROWS: {} ; as %: {:.2f}%\\r\\n'.format(invalid_rows.sum(),invalid_rows.mean()*100))\n",
    "    \n",
    "\n",
    "## ----------- REEMPLAZO TEXTO POR CODIGOS -------------\n",
    "\n",
    "mysql = F.f_make_mysql_connection('empresas')\n",
    "with mysql.cursor() as cur:\n",
    "    cur.execute('select * from look_provincia')\n",
    "    \n",
    "    look_provincia = {prov: cod for cod, prov in cur.fetchall()}\n",
    "    \n",
    "    cur.execute('select * from look_tipo_societario')\n",
    "    \n",
    "    look_tipo_societario = {soc: cod for cod, soc in cur.fetchall()}    \n",
    "    \n",
    "    cur.execute('select cd_estado_domicilio, nb_estado_domicilio from look_estado_domicilio')\n",
    "    \n",
    "    look_estado_domicilio = {est: cod for cod, est in cur.fetchall()}\n",
    "    \n",
    "rns['cd_provincia_dom_fiscal'] = rns['dom_fiscal_provincia'].apply(lambda x: look_provincia.get(x, -1))\n",
    "rns['cd_provincia_dom_legal'] = rns['dom_legal_provincia'].apply(lambda x: look_provincia.get(x, -1))\n",
    "rns['cd_estado_dom_fiscal'] = rns['dom_fiscal_estado_domicilio'].apply(lambda x: look_estado_domicilio.get(x, -1))\n",
    "rns['cd_estado_dom_legal'] = rns['dom_legal_estado_domicilio'].apply(lambda x: look_estado_domicilio.get(x, -1))\n",
    "rns['cd_tipo_societario'] = rns['tipo_societario'].apply(lambda x: look_tipo_societario.get(x, -1))\n",
    "\n",
    "with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "    \n",
    "    log.write('Reemplazo codigos de provincias, tipo societario y estado del domicilio -> OK\\r\\n')\n",
    "    \n",
    "## ------------------ BASE FINAL ------------------------\n",
    "\n",
    "rns.rename(columns= {'cuit': 'nu_cuit',\n",
    "                     'razon_social': 'nb_razon_social',\n",
    "                     'dom_fiscal_localidad': 'nb_localidad_dom_fiscal',\n",
    "                     'dom_fiscal_cp': 'cd_postal_dom_fiscal',\n",
    "                     'dom_fiscal_calle': 'nb_calle_dom_fiscal',\n",
    "                     'dom_fiscal_numero': 'nu_calle_dom_fiscal',\n",
    "                     'dom_fiscal_piso': 'tx_piso_dom_fiscal',\n",
    "                     'dom_fiscal_departamento': 'tx_depto_dom_fiscal',\n",
    "                     'dom_legal_localidad': 'nb_localidad_dom_legal',\n",
    "                     'dom_legal_cp': 'cd_postal_dom_legal',\n",
    "                     'dom_legal_calle': 'nb_calle_dom_legal',\n",
    "                     'dom_legal_numero': 'nu_calle_dom_legal',\n",
    "                     'dom_legal_piso': 'tx_piso_dom_legal',\n",
    "                     'dom_legal_departamento': 'tx_depto_dom_legal'},\n",
    "           inplace= True)\n",
    "\n",
    "with open(f'../logs/log_{file_path[-10:-4]}.txt', 'a') as log:\n",
    "    \n",
    "    log.write('Me quedo con la base final para actualizar\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_finales = ['nu_cuit', 'nb_razon_social', 'cd_tipo_societario', 'fh_contrato_social', 'fh_actualizacion',\n",
    "                     'cd_provincia_dom_fiscal', 'nb_localidad_dom_fiscal', 'cd_postal_dom_fiscal',\n",
    "                     'nb_calle_dom_fiscal', 'nu_calle_dom_fiscal', 'tx_piso_dom_fiscal', 'tx_depto_dom_fiscal','cd_estado_dom_fiscal',\n",
    "                     'cd_provincia_dom_legal', 'nb_localidad_dom_legal', 'cd_postal_dom_legal',\n",
    "                     'nb_calle_dom_legal', 'nu_calle_dom_legal', 'tx_piso_dom_legal', 'tx_depto_dom_legal','cd_estado_dom_legal',\n",
    "                     'fh_inicio_registro','fh_fin_registro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rns_final = rns[variables_finales[:-2]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rns_final.loc[:,'fh_inicio_registro'] = '1900-01-01'\n",
    "rns_final.loc[:,'fh_fin_registro'] = '2100-12-31'\n",
    "rns_final.loc[:,['fh_contrato_social','fh_actualizacion']] = rns_final.select_dtypes('datetime').apply(lambda x: x.dt.date.astype('string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Commited: chunk\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with mysql.cursor() as cur:\n",
    "    \n",
    "    n = len(variables_finales)\n",
    "    sql = 'insert into `registro_sociedades` (`{}`) values ({}%s)'.format('`,`'.join(variables_finales), '%s,'*(n-1))\n",
    "    \n",
    "\n",
    "    n = rns_final.shape[0]\n",
    "    i = 0\n",
    "    chunks = F.f_get_chunks(n)\n",
    "    while chunks:\n",
    "        chunk = chunks.pop(0)\n",
    "        null_to_none = np.where(rns_final.iloc[i:chunk,:].isnull(),None,rns_final.iloc[i:chunk,:])\n",
    "        list_input = null_to_none.tolist()\n",
    "        \n",
    "        cur.executemany(sql, list_input)\n",
    "        mysql.commit()    \n",
    "        \n",
    "        print(f'Commited: {chunk}')\n",
    "        i = chunk\n",
    "\n",
    "mysql.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
