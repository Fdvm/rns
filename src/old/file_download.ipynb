{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, last_date_updated):\n",
    "    '''\n",
    "        Se fija que archivos estan disponibles en la pagina y actualiza el mes siguiente a last_date_updated\n",
    "        \n",
    "        input:\n",
    "            url: Web de donde se descargan los datos\n",
    "            last_date_updated: string, AAAAMM fecha de la ultima actualizacion\n",
    "        output:\n",
    "            num_files_extracted: Cantidad de archivos a actualizar. 0 si no hay archivos.\n",
    "    '''\n",
    "\n",
    "    import re\n",
    "    import urllib.request, urllib.parse\n",
    "    import resquest\n",
    "    from bs4 import BeautifulSoup\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    zips = [tag['href'] for tag in soup.find_all('a') if re.match('.*registro-nacional-sociedades-\\d{4}.*\\.zip', tag['href']) is not None]\n",
    "    \n",
    "    last_zip_url, next_date_to_update = get_file_path_to_update(zips, last_date_updated)\n",
    "    \n",
    "    num_files_extracted = 0\n",
    "    if last_zip_url != None:\n",
    "        r = requests.get(last_zip_url, stream= True)\n",
    "        zip_file = '../data/zip/' + re.findall('registro.*', last_zip_url)[0]\n",
    "\n",
    "        with open(zip_file, 'wb') as zipf:\n",
    "            for chunk in r.iter_content(chunk_size= 1024 * 1024 * 10):\n",
    "                zipf.write(chunk)\n",
    "\n",
    "        # Exraigo unicamente los archivos que voy a usar\n",
    "        with ZipFile(zip_file, 'r') as zipf:\n",
    "            for file in zipf.namelist():\n",
    "                if re.findall('\\d{6}', file)[0] >= next_date_to_update:\n",
    "                    zipf.extract(file, '../data/zip')\n",
    "                    num_files_extracted += 1\n",
    "            \n",
    "    return num_files_extracted\n",
    "\n",
    "def get_file_path_to_update(zips, last_date_updated):\n",
    "\n",
    "    '''\n",
    "        Busco si hay archivos nuevos para actualizar y si hay devuelvo el path.\n",
    "        input:\n",
    "            zips: Lista de los paths de los archivos en la pagina\n",
    "            last_update: AAAAMM del ultimo archivo actualizado\n",
    "        output:\n",
    "            url_zip: string, path del archivo para actualizar o None si no hay archivos para actualizar\n",
    "            next_date_to_update: string, AAAAMM del proximo periodo a actualizar\n",
    "    '''\n",
    "    \n",
    "    if last_date_updated[-2:] < '12':\n",
    "        next_date_to_update = str(int(last_date_updated)+1)\n",
    "    else:\n",
    "        next_date_to_update = str((int(last_date_updated[:4])+1)*100+1)\n",
    "        \n",
    "    url_zips = [url_zip for url_zip in zips if re.match(f'.*registro-nacional-sociedades-{next_date_to_update[:4]}.*', url_zip) is not None]\n",
    "        \n",
    "    if len(url_zips) < 0:\n",
    "        url_zip = None\n",
    "    elif len(url_zips) == 1:\n",
    "        url_zip = url_zips[0]\n",
    "    elif len(url_zips) == 2:\n",
    "        if url_zips[0][-14:] > url_zips[1][-14:]:\n",
    "            url_zip = url_zips[0]\n",
    "        else:\n",
    "            url_zip = url_zips[1]\n",
    "    else:\n",
    "        raise ValueError('Hay mas archivos de los que corresponden.')\n",
    "        \n",
    "    return url_zip,next_date_to_update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
